import os
import logging
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† .env
load_dotenv()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(level=logging.INFO)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
WELCOME_MESSAGE = """
ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø°ÙƒÙŠ!

ğŸ¤– Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ± Ù…Ø¨Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª OpenAI (ChatGPT).

ğŸ§  ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„Ù‡ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ÙˆØ³ÙŠØ±Ø¯ Ø¹Ù„ÙŠÙƒ ÙÙˆØ±Ø§Ù‹ Ø¨Ø¥Ø¬Ø§Ø¨Ø§Øª Ø°ÙƒÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø©.

ğŸ’¡ ØªÙ… ØªØ·ÙˆÙŠØ± Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª Ø¨ÙˆØ§Ø³Ø·Ø©: *Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù† Ø¬Ù…Ø§Ù„ Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø¨ Ø§Ù„Ø¹Ø·Ø§Ø³*
"""

# Ø£Ù…Ø± /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(WELCOME_MESSAGE, parse_mode='Markdown')

# Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": user_input}],
            max_tokens=1000,
            temperature=0.7
        )
        answer = response["choices"][0]["message"]["content"]
        await update.message.reply_text(answer)
    except Exception as e:
        await update.message.reply_text("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI: " + str(e))

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    print("Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†...")
    app.run_polling()
